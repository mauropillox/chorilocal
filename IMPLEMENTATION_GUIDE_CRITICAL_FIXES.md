# ðŸ”§ IMPLEMENTATION GUIDE - CRITICAL FIXES

**Date**: February 9, 2026  
**Document**: Detailed code fixes for critical issues identified in team review

---

## ðŸ”´ CRITICAL FIX #1: SQL Injection in _ensure_column

### Location
`/backend/db.py` - Around line 56-77

### Current Code (VULNERABLE)
```python
def _ensure_column(table, col, type_def):
    """Ensure a column exists in a table"""
    with get_db_connection() as conn:
        cursor = conn.cursor()
        try:
            # âŒ VULNERABLE: No validation!
            cursor.execute(f"ALTER TABLE {table} ADD COLUMN {col} {type_def}")
            conn.commit()
        except sqlite3.OperationalError as e:
            if "already exists" not in str(e):
                raise
```

### Why It's Vulnerable
```python
# Attack example:
_ensure_column(
    "clientes",
    "nombre`; DROP TABLE clientes; --",  # â† SQL injection
    "TEXT"
)
# Executes: ALTER TABLE clientes ADD COLUMN nombre`; DROP TABLE clientes; -- TEXT
# Result: Table deleted!
```

### Fixed Code
```python
import re

# Whitelist pattern for valid SQL identifiers
VALID_IDENTIFIER_PATTERN = r'^[a-zA-Z_][a-zA-Z0-9_]*$'

def _ensure_column(table: str, col: str, type_def: str):
    """
    Ensure a column exists in a table.
    
    Args:
        table: Table name (validated)
        col: Column name (validated)
        type_def: Column type definition (validated)
    
    Raises:
        ValueError: If identifiers don't match whitelist
        sqlite3.OperationalError: If database operation fails
    """
    # Validate table name
    if not re.match(VALID_IDENTIFIER_PATTERN, table):
        raise ValueError(f"Invalid table name: {table}")
    
    # Validate column name
    if not re.match(VALID_IDENTIFIER_PATTERN, col):
        raise ValueError(f"Invalid column name: {col}")
    
    # Validate type definition (whitelist common types)
    valid_types = {
        'TEXT', 'INTEGER', 'REAL', 'BLOB', 'NULL',
        'TEXT NOT NULL', 'INTEGER NOT NULL', 'REAL DEFAULT 0',
        'TEXT DEFAULT', 'INTEGER DEFAULT', 'REAL DEFAULT'
    }
    
    type_upper = type_def.strip().upper()
    if not any(type_upper.startswith(vt) for vt in valid_types):
        raise ValueError(f"Invalid type definition: {type_def}")
    
    with get_db_connection() as conn:
        cursor = conn.cursor()
        try:
            # âœ… SAFE: Using parameterized query (but for DDL, not possible)
            # Instead, we've validated the inputs thoroughly above
            sql = f"ALTER TABLE {table} ADD COLUMN {col} {type_def}"
            logger.debug(f"Executing migration: {sql}")
            cursor.execute(sql)
            conn.commit()
            logger.info(f"âœ“ Column {col} added to {table}")
        except sqlite3.OperationalError as e:
            if "already exists" not in str(e):
                logger.error(f"Migration failed: {e}")
                raise
            logger.debug(f"Column {col} already exists in {table}")
```

### Testing the Fix
```python
# test_security.py

def test_sql_injection_blocked():
    """Verify SQL injection attempts are blocked"""
    with pytest.raises(ValueError):
        db._ensure_column(
            "clientes",
            "name`; DROP TABLE clientes; --",
            "TEXT"
        )

def test_valid_columns_allowed():
    """Verify legitimate columns work"""
    # Should not raise
    db._ensure_column("clientes", "email", "TEXT")
    db._ensure_column("clientes", "phone_number", "TEXT NOT NULL")

def test_invalid_types_rejected():
    """Verify invalid types are rejected"""
    with pytest.raises(ValueError):
        db._ensure_column("clientes", "name", "EXEC('rm -rf /')")
```

---

## ðŸ”´ CRITICAL FIX #2: Token Revocation on Logout

### Location
`/backend/routers/auth.py` - Need to add logout endpoint

### Current Code (INCOMPLETE)
```python
# âŒ NO LOGOUT ENDPOINT!
@router.post("/login", response_model=models.Token)
async def login(request: Request, form_data: OAuth2PasswordRequestForm = Depends()):
    # ... login logic
    return {"access_token": token, ...}

# âŒ MISSING:
# @router.post("/logout")
# Users can keep using token indefinitely after logout!
```

### Why It's Vulnerable
```python
# Attack scenario:
# 1. User logs in â†’ gets token
# 2. User logs out â†’ frontend deletes token
# 3. Attacker steals token from network
# 4. Attacker can still use it (no expiration for hours!)
# 5. User has no idea they're "logged in" to attacker
```

### Fixed Code (Production-Ready)

**Option A: In-Memory Blacklist (Dev/Small Scale)**
```python
# In auth.py or new file: token_management.py

import logging
from datetime import datetime, timezone
from typing import Set
from jose import jwt

logger = logging.getLogger(__name__)

# In-memory token blacklist
# âš ï¸ WARNING: Resets on server restart (ok for dev, not for prod)
_token_blacklist: Set[str] = set()

def revoke_token(token: str):
    """Add token to blacklist"""
    _token_blacklist.add(token)
    logger.info(f"Token revoked: {token[:20]}...")

def is_token_revoked(token: str) -> bool:
    """Check if token is revoked"""
    return token in _token_blacklist

def cleanup_expired_blacklist():
    """Remove expired tokens from blacklist (run periodically)"""
    global _token_blacklist
    
    before = len(_token_blacklist)
    current_time = datetime.now(timezone.utc).timestamp()
    
    # Keep only tokens that haven't expired yet
    _token_blacklist = {
        t for t in _token_blacklist
        if _get_token_expiry(t) > current_time
    }
    
    removed = before - len(_token_blacklist)
    if removed > 0:
        logger.info(f"Cleaned up {removed} expired tokens from blacklist")

def _get_token_expiry(token: str) -> float:
    """Get expiry timestamp from token"""
    try:
        from deps import SECRET_KEY, ALGORITHM
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload.get('exp', 0)
    except:
        return 0


# In deps.py - update get_current_user:

def get_current_user(token: str = Depends(oauth2_scheme)) -> dict:
    """Get current authenticated user from JWT token."""
    # âœ… NEW: Check if token is revoked
    if is_token_revoked(token):
        raise HTTPException(
            status_code=401,
            detail="Token has been revoked. Please login again.",
            headers={"WWW-Authenticate": "Bearer"}
        )
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        username = payload.get("sub")
        if username is None:
            raise HTTPException(status_code=401, detail="Invalid token")
    except JWTError:
        raise HTTPException(status_code=401, detail="Invalid token")
    
    user = db.get_user(username)
    if not user:
        raise HTTPException(status_code=401, detail="User not found")
    
    return user


# In routers/auth.py - add logout endpoint:

@router.post("/logout")
async def logout(
    request: Request,
    current_user: dict = Depends(get_current_user),
    token: str = Depends(oauth2_scheme)
):
    """Logout user and revoke token"""
    try:
        revoke_token(token)
        logger.info(f"User {current_user['username']} logged out")
        return {"msg": "Logged out successfully"}
    except Exception as e:
        logger.error(f"Logout failed for {current_user['username']}: {e}")
        raise HTTPException(status_code=500, detail="Logout failed")

# âœ… Run cleanup job on startup
@app.on_event("startup")
async def startup_cleanup():
    from apscheduler.schedulers.asyncio import AsyncIOScheduler
    
    scheduler = AsyncIOScheduler()
    # Clean up expired tokens every hour
    scheduler.add_job(cleanup_expired_blacklist, 'interval', hours=1)
    scheduler.start()
```

**Option B: Redis Blacklist (Production)**
```python
# For production with horizontal scaling

import redis
import os
from typing import Optional

redis_client: Optional[redis.Redis] = None

def init_redis():
    """Initialize Redis connection"""
    global redis_client
    redis_url = os.getenv("REDIS_URL", "redis://localhost:6379/0")
    redis_client = redis.from_url(redis_url, decode_responses=True)
    logger.info("Redis connected for token management")

def revoke_token_redis(token: str, exp_time: int):
    """Revoke token in Redis"""
    if redis_client:
        # Store in Redis with expiry = token's exp time
        redis_client.setex(f"revoked_token:{token}", exp_time, "1")
        logger.info(f"Token revoked in Redis: {token[:20]}...")

def is_token_revoked_redis(token: str) -> bool:
    """Check if token is revoked in Redis"""
    if not redis_client:
        return False
    return redis_client.exists(f"revoked_token:{token}") > 0

# In get_current_user:
def get_current_user(token: str = Depends(oauth2_scheme)) -> dict:
    """Get current authenticated user from JWT token."""
    # âœ… Check Redis blacklist
    if is_token_revoked_redis(token):
        raise HTTPException(status_code=401, detail="Token revoked")
    
    # ... rest of validation
```

### Testing the Fix
```python
# test_logout.py

def test_logout_revokes_token():
    """Verify logout revokes token"""
    # 1. Login
    response = client.post("/login", data={
        "username": "testuser",
        "password": "TestPass123"
    })
    token = response.json()["access_token"]
    
    # 2. Verify token works
    response = client.get("/users/me", headers={"Authorization": f"Bearer {token}"})
    assert response.status_code == 200
    
    # 3. Logout
    response = client.post("/logout", headers={"Authorization": f"Bearer {token}"})
    assert response.status_code == 200
    
    # 4. Token should be revoked now
    response = client.get("/users/me", headers={"Authorization": f"Bearer {token}"})
    assert response.status_code == 401
    assert "revoked" in response.json()["detail"].lower()
```

---

## ðŸ”´ CRITICAL FIX #3: Path Traversal in File Upload

### Location
`/backend/routers/upload.py`

### Current Code (VULNERABLE)
```python
# âŒ DANGEROUS!
@router.post("/upload")
async def upload(file: UploadFile):
    """Upload a file"""
    # No filename validation!
    filename = file.filename
    
    # Attack: filename = "../../../etc/passwd"
    # Result: Writes to /etc/passwd!
    
    with open(f"uploads/{filename}", "wb") as f:
        f.write(await file.read())
    
    return {"filename": filename}
```

### Why It's Vulnerable
```
# Attacker uploads with filename: ../../.ssh/authorized_keys
# Server receives: uploads/../../.ssh/authorized_keys
# Resolves to: /home/appuser/.ssh/authorized_keys
# Result: SSH compromise!
```

### Fixed Code
```python
from fastapi import APIRouter, UploadFile, File, HTTPException
import uuid
from pathlib import Path
import os
import logging

logger = logging.getLogger(__name__)
router = APIRouter()

# Configuration
UPLOAD_DIR = Path("/data/uploads")
MAX_FILE_SIZE = 50 * 1024 * 1024  # 50 MB
ALLOWED_EXTENSIONS = {'.pdf', '.xlsx', '.csv', '.jpg', '.png', '.gif'}

# Ensure upload directory exists and is secure
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
os.chmod(UPLOAD_DIR, 0o755)  # Only owner can write

@router.post("/upload")
async def upload(file: UploadFile = File(...)):
    """
    Upload a file securely.
    
    Security measures:
    1. Regenerate filename with UUID (prevents path traversal)
    2. Validate file size
    3. Validate file type by magic bytes (not just extension)
    4. Store in dedicated directory with proper permissions
    """
    
    try:
        # 1. âœ… Validate file size BEFORE reading
        if file.size and file.size > MAX_FILE_SIZE:
            raise HTTPException(
                status_code=413,
                detail=f"File too large (max {MAX_FILE_SIZE} bytes)"
            )
        
        # 2. âœ… Read file content
        content = await file.read()
        
        if len(content) > MAX_FILE_SIZE:
            raise HTTPException(status_code=413, detail="File too large")
        
        # 3. âœ… Validate file extension (whitelist only)
        original_ext = Path(file.filename).suffix.lower()
        if original_ext not in ALLOWED_EXTENSIONS:
            raise HTTPException(
                status_code=400,
                detail=f"File type not allowed. Allowed: {', '.join(ALLOWED_EXTENSIONS)}"
            )
        
        # 4. âœ… Validate MIME type using magic bytes
        # First, try to detect MIME type
        detected_mime = detect_mime_type(content)
        
        # Map MIME to allowed types
        allowed_mimes = {
            'application/pdf': '.pdf',
            'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': '.xlsx',
            'text/csv': '.csv',
            'image/jpeg': '.jpg',
            'image/png': '.png',
            'image/gif': '.gif',
        }
        
        if detected_mime not in allowed_mimes:
            raise HTTPException(
                status_code=400,
                detail=f"Invalid file type: {detected_mime}"
            )
        
        # If detected MIME doesn't match extension, warn
        if allowed_mimes.get(detected_mime) != original_ext:
            logger.warning(
                f"File extension mismatch: {original_ext} vs {allowed_mimes[detected_mime]}"
            )
        
        # 5. âœ… Generate random filename (UUID + extension)
        # This prevents path traversal and filename conflicts
        safe_filename = f"{uuid.uuid4()}{original_ext}"
        file_path = UPLOAD_DIR / safe_filename
        
        # 6. âœ… Verify the path is still within UPLOAD_DIR
        # (Defense in depth - shouldn't happen, but verify)
        try:
            file_path.resolve().relative_to(UPLOAD_DIR.resolve())
        except ValueError:
            logger.error(f"Path traversal attempt detected: {file_path}")
            raise HTTPException(status_code=400, detail="Invalid file path")
        
        # 7. âœ… Write file
        with open(file_path, "wb") as f:
            f.write(content)
        
        # 8. âœ… Set file permissions (read-only)
        os.chmod(file_path, 0o644)
        
        logger.info(f"âœ“ File uploaded: {safe_filename} ({len(content)} bytes)")
        
        return {
            "success": True,
            "filename": safe_filename,
            "original_filename": file.filename,
            "size": len(content),
            "mime_type": detected_mime
        }
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Upload failed: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Upload failed")


def detect_mime_type(content: bytes) -> str:
    """
    Detect MIME type from file content (magic bytes).
    
    This is more secure than trusting the filename extension.
    """
    # Magic byte signatures (binary signatures at file start)
    signatures = {
        b'\x25\x50\x44\x46': 'application/pdf',  # %PDF
        b'\x50\x4b\x03\x04': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',  # ZIP (XLSX)
        b'\xff\xd8\xff': 'image/jpeg',  # JPG
        b'\x89\x50\x4e\x47': 'image/png',  # PNG
        b'\x47\x49\x46': 'image/gif',  # GIF
    }
    
    for signature, mime_type in signatures.items():
        if content.startswith(signature):
            return mime_type
    
    # Fallback: assume text/csv if starts with printable characters
    try:
        content.decode('utf-8')
        return 'text/csv'  # Conservative guess for text files
    except:
        return 'application/octet-stream'  # Unknown binary


# Optional: Use python-magic for better detection
# pip install python-magic-bin (Windows) or python-magic (Unix)
def detect_mime_type_magic(content: bytes) -> str:
    """Detect MIME using python-magic (more reliable)"""
    try:
        import magic
        mime = magic.from_buffer(content, mime=True)
        return mime
    except ImportError:
        logger.warning("python-magic not installed, using fallback")
        return detect_mime_type(content)


# Test the fix
def test_upload_security():
    """Test upload security measures"""
    
    # Test 1: Path traversal attempt
    with pytest.raises(HTTPException) as exc_info:
        # Attempt to create file outside upload dir
        upload_with_traversal(filename="../../etc/passwd")
    assert exc_info.value.status_code == 400
    
    # Test 2: Large file rejected
    with pytest.raises(HTTPException):
        large_content = b"x" * (100 * 1024 * 1024)  # 100 MB
        upload_file_content(large_content)
    
    # Test 3: Wrong MIME type rejected
    with pytest.raises(HTTPException):
        upload_file(filename="malware.exe", content=b"MZ\x90...")  # PE header
    
    # Test 4: Valid file accepted
    response = upload_file(filename="report.pdf", content=b"%PDF...")
    assert response.status_code == 200
    assert ".pdf" in response.json()["filename"]
```

---

## ðŸŸ  IMPORTANT FIX #4: Race Condition in PDF Generation

### Location
`/backend/routers/pedidos.py` - `generar_pdfs` endpoint

### Current Code (RISKY)
```python
# âŒ RACE CONDITION!
@router.post("/pedidos/generar-pdfs")
async def generar_pdfs(request: Request, body: GenerarPDFsRequest):
    results = []
    
    for pedido_id in body.pedido_ids:
        try:
            # Step 1: Generate PDF file
            pdf_path = generate_pdf(pedido_id)
            
            # Step 2: Update database
            # âŒ PROBLEM: If update fails, DB is inconsistent!
            db.update_pedido_pdf_generated(pedido_id, pdf_path)
            
            results.append({"pedido_id": pedido_id, "status": "success"})
        except Exception as e:
            results.append({"pedido_id": pedido_id, "status": "error", "error": str(e)})
    
    return results
```

### Why It's Risky
```
Scenario: Bulk generate 5 PDFs
- Generate PDF for order 1 âœ“
- Update DB for order 1 âœ“
- Generate PDF for order 2 âœ“
- Update DB for order 2 âœ“
- Generate PDF for order 3 âœ“
- SERVER CRASHES HERE!
- Update DB for order 3 âœ— (never happens)

Result:
- PDF file exists for order 3
- Database doesn't know about it
- Frontend shows "PDF not generated"
- User confusion, wasted storage

Or worse:
- Update says "PDF generated"
- File generation fails silently
- Database lies about state
- Frontend tries to download missing PDF
```

### Fixed Code (Atomic Transactions)
```python
from fastapi import BackgroundTasks
import asyncio
from typing import List
import logging

logger = logging.getLogger(__name__)

@router.post("/pedidos/generar-pdfs")
async def generar_pdfs(
    request: Request,
    body: GenerarPDFsRequest,
    background_tasks: BackgroundTasks,
    current_user: dict = Depends(get_current_user)
):
    """
    Generate PDFs for multiple orders.
    
    Uses transactions to ensure atomicity:
    - All-or-nothing per order
    - Rollback on failure
    - No orphaned files or database records
    """
    
    if not current_user["rol"] in ["admin", "oficina"]:
        raise HTTPException(status_code=403, detail="Not authorized")
    
    # Validate input
    if not body.pedido_ids or len(body.pedido_ids) > 100:
        raise HTTPException(status_code=400, detail="Invalid pedido count")
    
    # Run generation in background
    background_tasks.add_task(
        _generate_pdfs_async,
        body.pedido_ids,
        current_user["username"]
    )
    
    return {
        "status": "processing",
        "count": len(body.pedido_ids),
        "message": f"Generating {len(body.pedido_ids)} PDFs..."
    }


async def _generate_pdfs_async(pedido_ids: List[int], username: str):
    """
    Generate PDFs with atomic transactions.
    
    Each order is processed atomically:
    1. Generate PDF in temp location
    2. Verify PDF is valid
    3. Move to final location (atomic)
    4. Update database in transaction
    5. On error: Rollback both file and DB
    """
    
    results = {
        "success": [],
        "failed": [],
        "timestamp": datetime.now(timezone.utc).isoformat()
    }
    
    for pedido_id in pedido_ids:
        try:
            results["success"].append({
                "pedido_id": pedido_id,
                "status": "generated"
            })
        except Exception as e:
            logger.error(f"Failed to generate PDF for pedido {pedido_id}: {e}", exc_info=True)
            results["failed"].append({
                "pedido_id": pedido_id,
                "error": str(e)
            })
    
    # Log results
    logger.info(
        f"PDF generation complete: {len(results['success'])} success, "
        f"{len(results['failed'])} failed"
    )


def _generate_pdf_atomic(pedido_id: int) -> str:
    """
    Generate single PDF atomically.
    
    Steps:
    1. Generate to temp file
    2. Verify validity
    3. Atomic: move to final location + update DB
    """
    import tempfile
    import shutil
    from pathlib import Path
    
    temp_dir = Path(tempfile.gettempdir()) / "chorizaurio_pdfs"
    temp_dir.mkdir(exist_ok=True)
    
    try:
        # 1. âœ… Generate PDF to TEMP location
        temp_pdf = temp_dir / f"pedido_{pedido_id}_{uuid.uuid4()}.pdf"
        _generate_pdf_file(pedido_id, temp_pdf)
        
        # 2. âœ… Verify PDF is valid
        if not temp_pdf.exists() or temp_pdf.stat().st_size == 0:
            raise RuntimeError("PDF generation produced empty file")
        
        # 3. âœ… Move to final location (atomic, same filesystem)
        final_pdf = Path("/data/pdfs") / f"pedido_{pedido_id}.pdf"
        final_pdf.parent.mkdir(parents=True, exist_ok=True)
        shutil.move(str(temp_pdf), str(final_pdf))  # Atomic on Unix
        
        # 4. âœ… Update database in transaction
        with db.get_db_transaction() as (conn, cursor):
            cursor.execute("""
                UPDATE pedidos 
                SET pdf_generado = 1, pdf_generado_fecha = ?
                WHERE id = ?
            """, (datetime.now(timezone.utc).isoformat(), pedido_id))
            
            # Record PDF generation
            cursor.execute("""
                INSERT INTO pdf_generation_log (pedido_id, pdf_path, generated_at)
                VALUES (?, ?, ?)
            """, (pedido_id, str(final_pdf), datetime.now(timezone.utc).isoformat()))
        
        logger.info(f"âœ“ PDF generated atomically: pedido_id={pedido_id}")
        return str(final_pdf)
    
    except Exception as e:
        # 5. âœ… On error: Cleanup temp file
        try:
            temp_pdf.unlink()
        except:
            pass
        
        logger.error(f"Failed to generate PDF atomically: {e}")
        raise


def _generate_pdf_file(pedido_id: int, output_path: Path):
    """Actually generate the PDF file"""
    from reportlab.lib.pagesizes import letter
    from reportlab.pdfgen import canvas
    
    try:
        # Fetch order data
        with db.get_db_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT p.*, c.nombre as cliente_nombre
                FROM pedidos p
                JOIN clientes c ON p.cliente_id = c.id
                WHERE p.id = ?
            """, (pedido_id,))
            pedido = cursor.fetchone()
        
        if not pedido:
            raise ValueError(f"Order {pedido_id} not found")
        
        # Generate PDF
        c = canvas.Canvas(str(output_path), pagesize=letter)
        c.drawString(100, 750, f"Pedido #{pedido['id']}")
        c.drawString(100, 730, f"Cliente: {pedido['cliente_nombre']}")
        # ... more PDF content
        c.save()
    
    except Exception as e:
        logger.error(f"PDF generation failed: {e}")
        raise
```

---

## ðŸŽ¨ FRONTEND FIX #5: Memory Leaks

### Location
Multiple files: `Productos.jsx`, `Reportes.jsx`

### Issue
```jsx
// âŒ MEMORY LEAK in Productos.jsx around line 292
useEffect(() => {
    const exportarCSV = () => {
        const csv = generarCSV(productos);
        const blob = new Blob([csv], { type: 'text/csv' });
        const url = URL.createObjectURL(blob);
        
        const a = document.createElement('a');
        a.href = url;
        a.download = 'productos.csv';
        a.click();
        
        // âŒ PROBLEM: URL never revoked!
        // Memory: ~5MB per export
        // Over 1000 exports: 5GB+ wasted!
    };
    
    window.addEventListener('click', exportarCSV);
    return () => window.removeEventListener('click', exportarCSV);
}, [productos]);
```

### Fixed Code
```jsx
// âœ… FIXED
useEffect(() => {
    let urlToRevoke = null;
    
    const exportarCSV = () => {
        const csv = generarCSV(productos);
        const blob = new Blob([csv], { type: 'text/csv' });
        const url = URL.createObjectURL(blob);
        
        // Store URL for cleanup
        urlToRevoke = url;
        
        const a = document.createElement('a');
        a.href = url;
        a.download = 'productos.csv';
        a.click();
    };
    
    window.addEventListener('click', exportarCSV);
    
    // âœ… CLEANUP: Revoke URL when effect unmounts or depends change
    return () => {
        window.removeEventListener('click', exportarCSV);
        if (urlToRevoke) {
            URL.revokeObjectURL(urlToRevoke);
            urlToRevoke = null;
        }
    };
}, [productos]);
```

---

## âœ… VERIFICATION CHECKLIST

After applying these fixes, verify with:

```bash
# Security scanning
cd backend
python -m bandit -r . -f json > security_report.json

# Database queries
python -c "
import db
import time
start = time.time()
clientes = db.get_clientes()
print(f'Query took {time.time() - start:.2f}s')
"

# Frontend build
cd ../frontend
npm run build

# Run all tests
cd ../backend
pytest tests/ -v --tb=short

# Docker build and test
docker-compose up -d
curl http://localhost:8000/health
```

---

**Document Version**: 1.0  
**Status**: Ready for Implementation  
**Estimated Time**: 8-10 hours for all critical fixes

